{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ME5311-PROJECT:\n",
    "# Climate Data Analysis: Sea Level Pressure and Two-Meter Temperature Data  Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import xarray as xr\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:46.252913800Z",
     "start_time": "2024-02-26T17:55:43.968708700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dimensions of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "n_samples = 16071\n",
    "n_latitudes = 101\n",
    "n_longitudes = 161\n",
    "shape = (n_samples, n_latitudes, n_longitudes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:46.284177700Z",
     "start_time": "2024-02-26T17:55:46.252913800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_slp:<xarray.Dataset> Size: 1GB\n",
      "Dimensions:    (time: 16071, longitude: 161, latitude: 101)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 129kB 1979-01-01T11:30:00 ... 2022-12-31...\n",
      "  * longitude  (longitude) float32 644B 70.0 70.5 71.0 ... 149.0 149.5 150.0\n",
      "  * latitude   (latitude) float32 404B 40.0 39.5 39.0 38.5 ... -9.0 -9.5 -10.0\n",
      "Data variables:\n",
      "    msl        (time, latitude, longitude) float32 1GB ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 1.9.3 (http://mpimet.mpg.de/...\n",
      "    history:      Mon Feb 05 11:54:26 2024: cdo -b 32 mergetime daily_slp1979...\n",
      "    Conventions:  CF-1.6\n",
      "    frequency:    day\n",
      "    CDO:          Climate Data Operators version 1.9.4rc1 (http://mpimet.mpg....\n",
      "ds_t2m:<xarray.Dataset> Size: 1GB\n",
      "Dimensions:    (time: 16071, longitude: 161, latitude: 101)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 129kB 1979-01-01T11:30:00 ... 2022-12-31...\n",
      "  * longitude  (longitude) float32 644B 70.0 70.5 71.0 ... 149.0 149.5 150.0\n",
      "  * latitude   (latitude) float32 404B 40.0 39.5 39.0 38.5 ... -9.0 -9.5 -10.0\n",
      "Data variables:\n",
      "    t2m        (time, latitude, longitude) float32 1GB ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 1.9.3 (http://mpimet.mpg.de/...\n",
      "    history:      Mon Feb 05 11:56:32 2024: cdo -b 32 mergetime daily_2m_temp...\n",
      "    Conventions:  CF-1.6\n",
      "    frequency:    day\n",
      "    CDO:          Climate Data Operators version 1.9.4rc1 (http://mpimet.mpg....\n"
     ]
    }
   ],
   "source": [
    "path = 'data'\n",
    "slp_path = os.path.join(path,'slp.nc')\n",
    "t2m_path = os.path.join(path,'t2m.nc')\n",
    "# load data\n",
    "ds_slp = xr.open_dataset(slp_path)  # Load sea level pressure data\n",
    "# print(f\"ds_slp:{ds_slp}\")\n",
    "ds_t2m = xr.open_dataset(t2m_path)  # Load two-meter temperature data\n",
    "# print(f\"ds_t2m:{ds_t2m}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:46.346753200Z",
     "start_time": "2024-02-26T17:55:46.268631100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get data values for sea level pressure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[101943.086 101989.92  102015.8   ... 101418.664 101386.12  101350.54 ]\n",
      "  [102027.68  102279.96  102562.85  ... 101468.    101434.67  101401.91 ]\n",
      "  [102285.22  102462.836 102559.64  ... 101519.43  101490.62  101461.56 ]\n",
      "  ...\n",
      "  [101111.01  101109.06  101107.54  ... 100526.9   100510.74  100511.875]\n",
      "  [101111.2   101109.19  101108.91  ... 100658.695 100566.766 100546.74 ]\n",
      "  [101112.44  101111.15  101109.95  ... 100591.01  100736.766 100558.74 ]]\n",
      "\n",
      " [[101900.16  101947.945 101967.85  ... 101238.516 101203.34  101165.47 ]\n",
      "  [102038.18  102291.54  102573.29  ... 101279.555 101243.47  101208.89 ]\n",
      "  [102372.15  102490.29  102545.21  ... 101317.945 101284.52  101252.086]\n",
      "  ...\n",
      "  [101124.08  101122.53  101119.734 ... 100458.69  100445.914 100452.65 ]\n",
      "  [101126.08  101124.484 101118.62  ... 100604.086 100507.03  100489.336]\n",
      "  [101126.445 101124.984 101117.35  ... 100552.    100682.836 100492.414]]\n",
      "\n",
      " [[101973.01  102020.375 102048.44  ... 101409.29  101399.12  101386.37 ]\n",
      "  [102356.09  102605.14  102854.93  ... 101434.38  101426.98  101419.54 ]\n",
      "  [102660.86  102736.86  102776.98  ... 101470.92  101464.77  101457.99 ]\n",
      "  ...\n",
      "  [101142.66  101141.266 101139.88  ... 100428.27  100415.32  100418.26 ]\n",
      "  [101147.15  101143.65  101141.484 ... 100574.72  100478.44  100464.46 ]\n",
      "  [101150.38  101146.89  101143.6   ... 100557.2   100682.96  100481.22 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[102812.33  102771.95  102793.195 ... 101029.914 100982.33  100934.37 ]\n",
      "  [102688.64  102800.875 102827.03  ... 101127.84  101078.2   101029.18 ]\n",
      "  [102745.08  102797.91  102734.305 ... 101224.766 101175.47  101125.94 ]\n",
      "  ...\n",
      "  [101376.96  101381.914 101385.79  ... 100982.68  100966.03  100965.38 ]\n",
      "  [101369.836 101375.33  101380.33  ... 101126.06  101021.836 100994.38 ]\n",
      "  [101369.73  101373.97  101376.98  ... 101120.234 101216.    100994.59 ]]\n",
      "\n",
      " [[103412.33  103456.875 103478.484 ... 101618.18  101598.53  101572.414]\n",
      "  [103469.99  103656.27  103740.27  ... 101647.984 101623.61  101598.914]\n",
      "  [103527.43  103557.16  103587.15  ... 101690.91  101659.2   101633.61 ]\n",
      "  ...\n",
      "  [101444.79  101444.47  101442.74  ... 100887.21  100845.84  100837.195]\n",
      "  [101446.81  101449.46  101447.984 ... 101032.99  100898.38  100881.305]\n",
      "  [101446.914 101450.39  101449.82  ... 101023.85  101118.57  100884.91 ]]\n",
      "\n",
      " [[103583.79  103599.62  103629.44  ... 101750.14  101745.36  101741.3  ]\n",
      "  [103780.68  103942.055 103967.414 ... 101774.4   101768.68  101763.35 ]\n",
      "  [103807.59  103841.3   103813.24  ... 101795.53  101788.336 101780.336]\n",
      "  ...\n",
      "  [101370.72  101371.2   101372.55  ... 100861.08  100838.73  100837.93 ]\n",
      "  [101379.98  101380.59  101378.734 ... 100994.88  100892.59  100874.375]\n",
      "  [101389.914 101388.46  101383.305 ... 100968.88  101074.336 100877.65 ]]]\n"
     ]
    }
   ],
   "source": [
    "da_slp_msl = ds_slp['msl']  # 'msl' is the variable name for sea level pressure\n",
    "x_slp = da_slp_msl.values\n",
    "# print(x_slp)\n",
    "# print(x_slp.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:47.868648700Z",
     "start_time": "2024-02-26T17:55:46.346753200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get data values for two-meter temperature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[273.28217 272.29355 272.3532  ... 278.57904 278.7337  278.90683]\n",
      "  [260.34695 257.77417 255.57187 ... 279.697   279.75113 279.85916]\n",
      "  [267.08688 265.21936 261.89755 ... 280.44757 280.40872 280.45724]\n",
      "  ...\n",
      "  [299.5844  299.59753 299.64648 ... 299.56076 300.1212  300.32434]\n",
      "  [299.5824  299.66254 299.65182 ... 297.05234 299.19998 299.27313]\n",
      "  [299.76086 299.7094  299.669   ... 296.93024 295.269   298.79196]]\n",
      "\n",
      " [[274.14554 274.5057  276.38028 ... 279.28534 279.46838 279.65353]\n",
      "  [261.9656  260.73248 259.91565 ... 280.26804 280.3096  280.36096]\n",
      "  [266.8752  264.50937 261.25928 ... 280.97006 280.9831  280.9806 ]\n",
      "  ...\n",
      "  [299.7329  299.81882 299.80908 ... 299.68384 300.15683 300.06952]\n",
      "  [299.7395  299.70724 299.9033  ... 296.7881  299.29776 298.99582]\n",
      "  [299.72818 299.77933 300.20435 ... 296.58835 295.2061  298.81598]]\n",
      "\n",
      " [[274.2645  275.10245 277.218   ... 281.18222 281.30457 281.47153]\n",
      "  [262.3486  260.37915 259.7292  ... 282.38742 282.32388 282.24146]\n",
      "  [266.22104 264.1264  260.57538 ... 283.0368  282.90646 282.8001 ]\n",
      "  ...\n",
      "  [300.2265  300.4137  300.5135  ... 299.38086 299.98553 299.85452]\n",
      "  [300.17413 300.36154 300.4574  ... 296.6168  298.9872  298.68933]\n",
      "  [300.16992 300.29745 300.30865 ... 295.97723 294.85416 298.84454]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[272.30435 272.048   272.85358 ... 279.0235  279.04147 279.12332]\n",
      "  [260.04126 258.96167 258.60986 ... 279.60556 279.71368 279.85162]\n",
      "  [267.46387 266.34354 262.60602 ... 280.41953 280.6316  280.72174]\n",
      "  ...\n",
      "  [300.36508 300.24463 300.24487 ... 300.05325 300.43832 300.45908]\n",
      "  [300.94058 300.79272 300.60422 ... 297.30408 299.70874 299.87415]\n",
      "  [300.6749  300.73178 300.773   ... 296.8275  295.6642  299.82077]]\n",
      "\n",
      " [[272.11813 271.4228  270.96463 ... 277.75333 277.53653 277.47058]\n",
      "  [258.42038 257.6199  256.53394 ... 278.53336 278.43063 278.30447]\n",
      "  [267.3897  266.25085 262.1482  ... 279.30365 279.30942 279.06   ]\n",
      "  ...\n",
      "  [300.76385 300.7388  300.8378  ... 299.6778  300.76874 301.35974]\n",
      "  [300.90372 300.72348 300.7474  ... 296.12448 299.64816 299.5798 ]\n",
      "  [300.99393 300.8176  300.73135 ... 295.42783 294.3896  299.4558 ]]\n",
      "\n",
      " [[271.37567 269.86725 270.73712 ... 278.6246  278.62976 278.64117]\n",
      "  [256.98544 256.56815 257.14905 ... 278.98853 278.8863  278.89294]\n",
      "  [265.1043  263.81915 259.79843 ... 279.6799  279.45987 279.3235 ]\n",
      "  ...\n",
      "  [301.0603  300.63986 300.4167  ... 300.0682  300.82294 301.12906]\n",
      "  [300.452   300.10974 299.9827  ... 296.92596 299.64618 299.77063]\n",
      "  [299.8044  299.56604 299.56323 ... 297.00284 295.61908 299.67285]]]\n"
     ]
    }
   ],
   "source": [
    "da_t2m_t2m = ds_t2m['t2m']  # 't2m' is the variable name for two-meter temperature\n",
    "x_t2m = da_t2m_t2m.values\n",
    "print(x_t2m)\n",
    "# print(x_t2m.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.019957700Z",
     "start_time": "2024-02-26T17:55:47.868648700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get time snapshots from sea level pressure dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1979-01-01T11:30:00.000000000' '1979-01-02T11:30:00.000000000'\n",
      " '1979-01-03T11:30:00.000000000' ... '2022-12-29T11:30:00.000000000'\n",
      " '2022-12-30T11:30:00.000000000' '2022-12-31T11:30:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "da_slp_time = ds_slp['time']\n",
    "t_slp = da_slp_time.values\n",
    "print(t_slp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.035597700Z",
     "start_time": "2024-02-26T17:55:50.019957700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get time snapshots from two-meter temperature dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1979-01-01T11:30:00.000000000' '1979-01-02T11:30:00.000000000'\n",
      " '1979-01-03T11:30:00.000000000' ... '2022-12-29T11:30:00.000000000'\n",
      " '2022-12-30T11:30:00.000000000' '2022-12-31T11:30:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "da_t2m_time = ds_t2m['time']\n",
    "t_t2m = da_t2m_time.values\n",
    "print(t_t2m)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.129351400Z",
     "start_time": "2024-02-26T17:55:50.035597700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get longitude values from sea level pressure dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 70.   70.5  71.   71.5  72.   72.5  73.   73.5  74.   74.5  75.   75.5\n",
      "  76.   76.5  77.   77.5  78.   78.5  79.   79.5  80.   80.5  81.   81.5\n",
      "  82.   82.5  83.   83.5  84.   84.5  85.   85.5  86.   86.5  87.   87.5\n",
      "  88.   88.5  89.   89.5  90.   90.5  91.   91.5  92.   92.5  93.   93.5\n",
      "  94.   94.5  95.   95.5  96.   96.5  97.   97.5  98.   98.5  99.   99.5\n",
      " 100.  100.5 101.  101.5 102.  102.5 103.  103.5 104.  104.5 105.  105.5\n",
      " 106.  106.5 107.  107.5 108.  108.5 109.  109.5 110.  110.5 111.  111.5\n",
      " 112.  112.5 113.  113.5 114.  114.5 115.  115.5 116.  116.5 117.  117.5\n",
      " 118.  118.5 119.  119.5 120.  120.5 121.  121.5 122.  122.5 123.  123.5\n",
      " 124.  124.5 125.  125.5 126.  126.5 127.  127.5 128.  128.5 129.  129.5\n",
      " 130.  130.5 131.  131.5 132.  132.5 133.  133.5 134.  134.5 135.  135.5\n",
      " 136.  136.5 137.  137.5 138.  138.5 139.  139.5 140.  140.5 141.  141.5\n",
      " 142.  142.5 143.  143.5 144.  144.5 145.  145.5 146.  146.5 147.  147.5\n",
      " 148.  148.5 149.  149.5 150. ]\n"
     ]
    }
   ],
   "source": [
    "da_slp_longitude = ds_slp['longitude']\n",
    "lon_slp = da_slp_longitude.values\n",
    "print(lon_slp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.149870400Z",
     "start_time": "2024-02-26T17:55:50.051285700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get latitude values from sea level pressure dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40.   39.5  39.   38.5  38.   37.5  37.   36.5  36.   35.5  35.   34.5\n",
      "  34.   33.5  33.   32.5  32.   31.5  31.   30.5  30.   29.5  29.   28.5\n",
      "  28.   27.5  27.   26.5  26.   25.5  25.   24.5  24.   23.5  23.   22.5\n",
      "  22.   21.5  21.   20.5  20.   19.5  19.   18.5  18.   17.5  17.   16.5\n",
      "  16.   15.5  15.   14.5  14.   13.5  13.   12.5  12.   11.5  11.   10.5\n",
      "  10.    9.5   9.    8.5   8.    7.5   7.    6.5   6.    5.5   5.    4.5\n",
      "   4.    3.5   3.    2.5   2.    1.5   1.    0.5   0.   -0.5  -1.   -1.5\n",
      "  -2.   -2.5  -3.   -3.5  -4.   -4.5  -5.   -5.5  -6.   -6.5  -7.   -7.5\n",
      "  -8.   -8.5  -9.   -9.5 -10. ]\n"
     ]
    }
   ],
   "source": [
    "da_slp_latitude = ds_slp['latitude']\n",
    "lat_slp = da_slp_latitude.values\n",
    "print(lat_slp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.149870400Z",
     "start_time": "2024-02-26T17:55:50.067055300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ONLY if not enough memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# OPTIONAL: Reduce resolution if not enough memory\n",
    "# Reduce resolution for sea level pressure dataset\n",
    "# low_res_ds_slp = ds_slp[{'longitude': slice(None, None, 2), 'latitude': slice(None, None, 2)}]\n",
    "# low_res_ds_slp.to_netcdf(path='slp_low_res.nc')\n",
    "#\n",
    "# # Reduce resolution for two-meter temperature dataset\n",
    "# low_res_ds_t2m = ds_t2m[{'longitude': slice(None, None, 2), 'latitude': slice(None, None, 2)}]\n",
    "# low_res_ds_t2m.to_netcdf(path='t2m_low_res.nc')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:55:50.149870400Z",
     "start_time": "2024-02-26T17:55:50.082458700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series Forecasting with LSTM: Sea Level Pressure and Two-Meter Temperature Data  Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "data load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataset complete!\n",
      "train and test  dataset complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "D:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0000\n",
      "Epoch [2/5], Loss: 0.0000\n",
      "Epoch [3/5], Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 91\u001B[0m\n\u001B[0;32m     89\u001B[0m X_batch, y_batch \u001B[38;5;241m=\u001B[39m X_batch\u001B[38;5;241m.\u001B[39mto(device), y_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     90\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 91\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[0;32m     93\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[11], line 49\u001B[0m, in \u001B[0;36mLSTMModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     47\u001B[0m c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dim, device\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     48\u001B[0m out, (hn, cn) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm(x, (h0, c0))\n\u001B[1;32m---> 49\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\ME5311_Project_Data_Analysis\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "path = 'data'\n",
    "slp_path = os.path.join(path, 'slp.nc')\n",
    "t2m_path = os.path.join(path, 't2m.nc')\n",
    "\n",
    "ds_slp = xr.open_dataset(slp_path)\n",
    "ds_t2m = xr.open_dataset(t2m_path)\n",
    "\n",
    "# 降低分辨率\n",
    "low_res_ds_slp = ds_slp[{'longitude': slice(None, None, 2), 'latitude': slice(None, None, 2)}]\n",
    "low_res_ds_slp.to_netcdf(path='slp_low_res.nc')\n",
    "\n",
    "low_res_ds_t2m = ds_t2m[{'longitude': slice(None, None, 2), 'latitude': slice(None, None, 2)}]\n",
    "low_res_ds_t2m.to_netcdf(path='t2m_low_res.nc')\n",
    "\n",
    "\n",
    "ds_slp_lr = xr.open_dataset('slp_low_res.nc')\n",
    "x_slp_lr = ds_slp_lr['msl'].values\n",
    "print(\"data load\")\n",
    "\n",
    "assert x_slp.shape[0] == x_t2m.shape[0], \"The number of samples must match\"\n",
    "\n",
    "\n",
    "x_combined = np.concatenate([x_slp, x_t2m], axis=-1)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled = scaler.fit_transform(x_combined)\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_prob=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 设置模型参数\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 1\n",
    "output_dim = 1\n",
    "dropout_prob = 0.5  # 设置 Dropout 概率\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim, dropout_prob).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 5\n",
    "time_step = 20\n",
    "\n",
    "x_scaled, y_scaled = create_dataset(x_scaled, time_step)\n",
    "print(\"create dataset complete!\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"train and test  dataset complete!\")\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train).unsqueeze(-1).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).unsqueeze(-1).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "batch_size = 128\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T18:39:13.334874600Z",
     "start_time": "2024-02-26T17:55:50.098098300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted_list = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in DataLoader(X_test_tensor, batch_size=64):\n",
    "        X_batch = X_batch.to(device)\n",
    "        output = model(X_batch).to('cpu').numpy()\n",
    "        predicted_list.append(output)\n",
    "\n",
    "predicted = np.concatenate(predicted_list, axis=0)\n",
    "\n",
    "predicted_rescaled = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算MSE和RMSE\n",
    "mse = mean_squared_error(y_test_rescaled, predicted_rescaled)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "\n",
    "# 计算R^2分数\n",
    "r2 = r2_score(y_test_rescaled, predicted_rescaled)\n",
    "print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "sampling_rate = 100\n",
    "# 绘制实际值与预测值\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(range(0, len(y_test_rescaled), sampling_rate), y_test_rescaled[::sampling_rate], label='Actual', color='blue', s=1)\n",
    "plt.scatter(range(0, len(predicted_rescaled), sampling_rate), predicted_rescaled[::sampling_rate], label='Predicted', color='red', s=1)\n",
    "plt.title('Actual vs Predicted Values (Sampled)')\n",
    "plt.xlabel('Sampled Number of Observations')\n",
    "plt.ylabel('Rescaled Values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
